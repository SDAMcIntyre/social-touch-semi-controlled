import os
import yaml
import copy
from pathlib import Path
from typing import Dict, Any, List, Set

from prefect import flow

import utils.path_tools as path_tools
from utils.pipeline_config_manager import DagConfigHandler

from primary_processing import (
    KinectConfigFileHandler,
    KinectConfig,
    get_block_files
)

from _3_preprocessing._1_sticker_tracking import (
    review_tracked_objects_in_video,
    review_xyz_stickers_with_forearm_pointcloud
)

from _3_preprocessing._2_hand_tracking import (
    select_hand_model_characteristics
)

from _3_preprocessing._3_forearm_extraction import (
    is_forearm_valid
)


# --- Sub-Flows (Manual Tasks) ---

@flow(name="Manual: Prepare Hand Model")
def prepare_hand_model(
    rgb_video_path: Path,
    hand_models_dir: Path,
    output_dir: Path
) -> Path:
    """Manually define landmarks for the 3D hand model."""
    print(f"[{output_dir.name}] Preparing hand tracking session...")
    name_baseline = rgb_video_path.stem + "_handmodel"
    metadata_path = output_dir / (name_baseline + "_metadata.json")

    point_labels = ["sticker_yellow", "sticker_blue", "sticker_green"]
    select_hand_model_characteristics(rgb_video_path, hand_models_dir, point_labels, metadata_path)
    return metadata_path

@flow(name="Manual: Review Stickers")
def review_2d_stickers(
    rgb_video_path: Path,
    root_output_dir: Path
) -> Path:
    """Manually define ROI and review sticker tracking."""
    output_dir = root_output_dir / "handstickers"
    output_dir.mkdir(parents=True, exist_ok=True)
    print(f"[{output_dir.name}] Reviewing sticker tracking...")

    name_baseline = rgb_video_path.stem + "_handstickers"
    metadata_roi_path = output_dir / (name_baseline + "_roi_metadata.json")
    stickers_roi_csv_path = output_dir / (name_baseline + "_roi_tracking.csv")

    review_tracked_objects_in_video(rgb_video_path, metadata_roi_path, stickers_roi_csv_path)
    return stickers_roi_csv_path


def review_xyz_stickers(
    xyz_sticker_csv_dir: Path,
    rgb_video_path: Path,
    session_common_dir: Path,
    session_id: str,
) -> Path:
    print(f"[{rgb_video_path.name}] Validating xyz stickers extraction...")
    forearm_pointcloud_dir = session_common_dir / "forearm_pointclouds"
    metadata_filaname = session_id + "_arm_roi_metadata.json"
    forearm_metadata_path = forearm_pointcloud_dir / metadata_filaname
    if not is_forearm_valid(forearm_pointcloud_dir):
        return False
    
    # Base name derived from the 2D tracking file for consistency
    name_baseline = rgb_video_path.stem.replace('_roi_tracking', '')
    xyz_csv_path = xyz_sticker_csv_dir / (name_baseline + "_handstickers_xyz_tracked.csv")
    xyz_md_path = xyz_sticker_csv_dir / (name_baseline + "_handstickers_xyz_tracked_metadata.json")
    review_xyz_stickers_with_forearm_pointcloud(xyz_csv_path, xyz_md_path, forearm_pointcloud_dir, forearm_metadata_path, rgb_video_path.name)

    return True
    


# --- The "Worker" Flow ---
@flow(name="Run Single Session Manual Pipeline")
def run_single_session_pipeline(
    config: KinectConfig,
    dag_handler: DagConfigHandler
):
    """Processes a single dataset by calling manual sub-routines based on DAG config."""
    block_name = config.source_video.name
    print(f"üöÄ Starting manual pipeline for block: {block_name}")
    
    # Assume the primary RGB video has been generated by the automatic pipeline.
    # This path is constructed based on convention.
    rgb_video_path = config.video_primary_output_dir / f"{config.source_video.stem}.mp4"
    if not rgb_video_path.exists():
        print(f"‚ùå Critical Error: RGB video not found at {rgb_video_path}.")
        print("Please run the 'generate_rgb_video' task from the automatic pipeline first.")
        return {"status": "failed", "error": "RGB video not found"}

    try:
        if dag_handler.can_run('review_2d_stickers'):
            print(f"[{block_name}] ==> Running task: review_2d_stickers")
            review_2d_stickers(
                rgb_video_path=rgb_video_path,
                root_output_dir=config.video_processed_output_dir
            )
            dag_handler.mark_completed('review_2d_stickers')

        if dag_handler.can_run('review_xyz_stickers'):
            print(f"[{block_name}] ==> Running task: review_xyz_stickers")
            valid_data =  review_xyz_stickers(
                xyz_sticker_csv_dir=config.video_processed_output_dir / "handstickers",
                rgb_video_path=rgb_video_path,
                session_common_dir=config.session_processed_output_dir,
                session_id=config.session_id
            )
            if valid_data:
                dag_handler.mark_completed('review_xyz_stickers')


        if dag_handler.can_run('prepare_hand_model'):
            print(f"[{block_name}] ==> Running task: prepare_hand_model")
            prepare_hand_model(
                rgb_video_path=rgb_video_path,
                hand_models_dir=config.hand_models_dir,
                output_dir=config.video_processed_output_dir
            )
            dag_handler.mark_completed('prepare_hand_model')

    except Exception as e:
        print(f"‚ùå Pipeline failed during manual processing. Error: {e}")
        return {"status": "failed", "error": str(e)}

    print(f"‚úÖ Manual pipeline finished for session: {block_name}")
    return {"status": "success", "completed_tasks": list(dag_handler.completed_tasks)}


# --- The "Dispatcher" Flow ---
@flow(name="Run Manual Batch Sequentially", log_prints=True)
def run_batch_sequentially(kinect_configs_dir: Path, project_data_root: Path, dag_config_path: Path):
    """Runs all session pipelines one by one, waiting for each to complete."""
    dag_handler_template = DagConfigHandler(dag_config_path)

    block_files = get_block_files(kinect_configs_dir)
    for block_file in block_files:
        print(f"--- Running session: {block_file.name} ---")
        try:
            config_data = KinectConfigFileHandler.load_and_resolve_config(block_file)
            validated_config = KinectConfig(config_data=config_data, database_path=project_data_root)
            dag_handler_instance = dag_handler_template.copy() # Use copy for a fresh run state
            
            result = run_single_session_pipeline(
                config=validated_config,
                dag_handler=dag_handler_instance
            )
            print(f"--- Completed session: {block_file.name} | Status: {result.get('status', 'unknown')} ---")
        except Exception as e:
            print(f"‚ùå Failed to initialize session {block_file.name}. Error: {e}")
            continue

    print("‚úÖ All sequential manual runs have completed.")


# --- Main execution block ---
if __name__ == "__main__":
    print("üõ†Ô∏è  Setting up files for manual processing...")

    project_data_root = path_tools.get_project_data_root()

    configs_dir = Path("configs")
    dag_config_path = configs_dir / "kinect_manual_pipeline_dag.yaml"

    try:
        main_dag_handler = DagConfigHandler(dag_config_path)
        kinect_dir = main_dag_handler.get_parameter('kinect_configs_directory')
        kinect_configs_dir = configs_dir / kinect_dir
    except FileNotFoundError:
        print(f"‚ùå Error: '{dag_config_path}' not found.")
        print("Please create the DAG config file for the manual pipeline and run again.")
        exit(1)

    print("üöÄ Launching manual batch processing SEQUENTIALLY.")
    run_batch_sequentially(
        kinect_configs_dir=kinect_configs_dir,
        project_data_root=project_data_root,
        dag_config_path=dag_config_path
    )